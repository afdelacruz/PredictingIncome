---
title: "FINAL"
author: "Andrew Dela Cruz"
date: "12/5/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(randomForest)
library(tree)
library(caret)
library(GGally)
library(rpart)
library(stringr)
```

DATA PREPROCESSING TODO LIST:
-Load data in 
-Create column names 
-Convert everything to correct data types (factors, numeric)
-Check for complete samples
-Check for outliers
-Create dummy variables
-Correlations
-Plots
-Summary Stats



#Loading Data
```{r}
raw_data = read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data",
                sep = ',', stringsAsFactors = F)

test_set = read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test",
                      sep = ',', skip = 1, stringsAsFactors = F)

test_set$V15 = str_replace(test_set$V15, "\\.", "")

AllData = rbind(raw_data, test_set)

column_names = c("age", "WorkClass", "FNLWGT", "Education", "EducationNum", "MartialStatus", "Occupation",
          "Relationship", "Race", "Sex", "CapitalGain", "CapitalLoss", "HoursWeek", 
          "NativeCountry", "Salary")
colnames(AllData) = column_names

ColClasses = sapply(AllData, class)

char_vars = names(AllData)[ColClasses=='character']

#Removing empty space at start, replacing ? with na
for (var in char_vars){
  AllData[,var] = str_trim(AllData[,var])
  AllData[AllData[,var]=='?', var] = NA
  AllData[,var] = factor(AllData[,var])
}
```

#Exploratory Data Analysis

##Missing Values
```{r}
summary(AllData)
```

Missing values:
  The majority of missing values come from the Occupation and WorkingClass columns. There is almost a complete overlap between those without information on occupation and those without info on working class. The only other column with missing values is `NativeCountry`. 
```{r}
##Deal with Missing Values
```

##Outliers

##Binning
```{r}
mean(AllData$CapitalGain>0)
mean(AllData$CapitalLoss>0)
CapitalChange = AllData$CapitalGain-AllData$CapitalLoss

AllData$Capital = NA
AllData[CapitalChange==0,'Capital'] = 'None'
AllData[CapitalChange<0,'Capital'] = 'Loss'
AllData[CapitalChange>0,'Capital'] = 'Gain'
AllData[CapitalChange==99999,'Capital'] = 'Max'
AllData[,c('CapitalGain', 'CapitalLoss')] = NULL
AllData$Capital = factor(AllData$Capital)
```

The columns `CapitalGain` and `CapitalLoss` can be combined, since a value in Gain automatically means there is a value in Loss, so we combine it into `CapitalChange`.

We can see that only 8% of people have `CapitalChange` over 100, 5% have less than -100, and 87% have exactly 0. Also, a few hundred cases have a `CapitalChange` value of 99999 which appears to be a max cap rather than a true value. Thus, we choose to bin `CapitalChange` into 4 levels: loss, none, gain, and max

##Changing Scales
```{r}
numerics = (sapply(AllData, class) == "integer")
AllData[,numerics] = scale(AllData[,numerics])
sapply(AllData[,numerics], sd)
```
Numeric columns of data are now mean-centered and scaled

##Dummy Indicators

##Summary Statistics
```{r}
summary(AllData)
```

##Visualizing Distributions
```{r}
num_vars = names(AllData)[numerics]

for(var in num_vars){
  hist(AllData[,var], main = var, xlab = var)
}

non_num_vars = names(AllData)[!numerics]
for (var in non_num_vars){
  plot(AllData[,var])
}
```

##Adjustments
```{r}
```

#Association between predictor and response

##Split Data
```{r}
Data = AllData[1:nrow(raw)]
```

#Classification Tree
```{r}
set.seed(2)
AllData$NativeCountry = NULL
AllData$EducationNum = NULL
Data = AllData[1:nrow(raw_data),]
Validation = AllData[(nrow(raw_data)+1):nrow(AllData),]


trainIndex = sample(nrow(Data),0.8*nrow(Data) )
Train = Data[trainIndex,]
test = Data[-trainIndex,]

tree.Salary = tree(Salary~., Train)
Salary.predict = predict(tree.Salary, Train, type = 'class')
confusionMatrix(Salary.predict, Train$Salary)
```

```{r}
set.seed(3)
class(tree.Salary)
cv.Salary = cv.tree(tree.Salary, FUN = prune.misclass)
names(cv.Salary)
par(mfrow = c(1,2))
plot(cv.Salary$size, cv.Salary$dev, type = 'b')
plot(cv.Salary$k, cv.Salary$dev, type = 'b')
```
```{r}
prune.8 = prune.misclass(tree.Salary, best = 8)
prune.5 = prune.misclass(tree.Salary, best = 5)

tree.pred8 = predict(prune.8,test, type = 'class')
tree.pred5 = predict(prune.5,test, type = 'class')
confusion.8 = confusionMatrix(tree.pred8,test$Salary)
confusion.5 = confusionMatrix(tree.pred5,test$Salary)
confusion.5
summary(prune.5)
```


###Single Tree
##adjusting complexity parameter
```{r}
#better = rpart(Salary ~., data = Data, cp = 0.001530417)
rpartTune = train(Data[,-ncol(Data)], Data[,"Salary"],
                  method = "rpart",
                  tuneLength = 10,
                  trControl = trainControl(method = "cv"))
rpartTune 
#rpart.Prune = prune(rpartTune, cp = 5, "CP")
posteriors.Tree = predict(rpartTune, test, type = 'prob', cp = 10)
predic.Tree = predict(rpartTune, newdata = test)
Conf.Tree = confusionMatrix(test$Salary, predic.Tree)
Conf.Tree
df.Tree = cbind(posteriors.Tree[,2], test$Salary)
preds.Tree = prediction(df.Tree[,1], df.Tree[,2])
ROC.Tree = performance(preds.Tree, measure = 'tpr', x.measure = 'fpr')
plot(ROC.Tree)
abline(a = 0, b = 1 , lty = 2)
auc.Tree = performance(preds.Tree, measure = 'auc')
auc.Tree@y.values

```
#Adjusting max depth 
```{r}
#better = rpart(Salary ~., data = Data, cp = 0.001530417)
rpartTune2 = train(Data[,-ncol(Data)], Data[,"Salary"],
                  method = "rpart2",
                  tuneLength = 10,
                  trControl = trainControl(method = "cv"))
rpartTune2
#rpart.Prune = prune(rpartTune, cp = 5, "CP")
posteriors.Tree = predict(rpartTune2, test, type = 'prob', cp = 10)
predic.Tree = predict(rpartTune, newdata = test)
Conf.Tree = confusionMatrix(test$Salary, predic.Tree)
Conf.Tree
df.Tree = cbind(posteriors.Tree[,2], test$Salary)
preds.Tree = prediction(df.Tree[,1], df.Tree[,2])
ROC.Tree = performance(preds.Tree, measure = 'tpr', x.measure = 'fpr')
plot(ROC.Tree)
abline(a = 0, b = 1 , lty = 2)
auc.Tree = performance(preds.Tree, measure = 'auc')
auc.Tree@y.values

```

Tuning complexity paramter increases accuracy more than adjusting depth. 


###Bagged Tree
```{r}
set.seed(34)
library(ipred)
library(randomForest)
p = ncol(Train)-1
#bag.Salary = bagging(Salary ~., data = Train)
#plot(bag.Salary)
bag.Salary = randomForest(Salary~.,
                          data = Train, 
                          mtry = p, 
                          importance = TRUE,
                          ntree = 500)
posteriors.Bagged = predict(bag.Salary, newdata = test, type = 'prob')
predic.Bagged = predict(bag.Salary, newdata = test, type = 'class')
Conf.Bagged = confusionMatrix(test$Salary, predic.Bagged)
Conf.Bagged
df.Bagged = cbind(posteriors.Bagged[,2], test$Salary)
preds.Bagged = prediction(df.Bagged[,1], df.Bagged[,2])
ROC.Bagged = performance(preds.Bagged, measure = 'tpr', x.measure = 'fpr')
plot(ROC.Bagged)
abline(a = 0, b = 1, lty = 2)
auc.Bagged <-performance(preds.Bagged, measure = 'auc')
auc.Bagged@y.values
importance(bag.Salary)
varImpPlot(bag.Salary)
```

```{r}
set.seed(29)
library(ROCR)
rfModel = tuneRF(Train[,-ncol(Train)], Train[,ncol(Train)], 
                 stepFactor=1.5,
                 doBest = TRUE,
                 improve=1e-5, 
                 ntree = 500)

summary(rfModel)
posteriors.rf = predict(rfModel, test, type = 'prob')
predic.rf = predict(rfModel, newdata = test)
Conf.rf = confusionMatrix(test$Salary, predic.rf)
Conf.rf
df.rf = cbind(posteriors.rf[,2], test$Salary)
preds.rf = prediction(df.rf[,1], df.rf[,2])
ROC.rf = performance(preds.rf, measure = 'tpr', x.measure = 'fpr')
plot(ROC.rf)
abline(a = 0, b = 1 , lty = 2)
auc.rf = performance(preds.rf, measure = 'auc')
auc.rf@y.values
importance(rfModel)
varImpPlot(rfModel)

```

###Tune RF with Caret but takes awhile
```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="random")
set.seed(2)
mtry <- sqrt(ncol(Train[,1:ncol(Train)]))
rf_random <- train(Salary~., data=Train, method="rf", metric="Accuracy", tuneLength=5, trControl=control)
print(rf_random)
plot(rf_random)
```


###Showing all models on Validation Set
```{r}
posteriors.Validate = predict(rpartTune, Validation, type = 'prob')
predic.Validate = predict(rfModel, newdata = Validation)
Conf.Validate = confusionMatrix(Validation$Salary, predic.Validate)
Conf.Validate
df.Validate = cbind(posteriors.Validate[,2], Validation$Salary)
preds.Validate = prediction(df.Validate[,1], df.Validate[,2])
ROC.Validate = performance(preds.Validate, measure = 'tpr', x.measure = 'fpr')
plot(ROC.Validate)
abline(a = 0, b = 1 , lty = 2)
auc.Validate = performance(preds.Validate, measure = 'auc')
auc.Validate@y.values
```

```{r}
posteriors.Validate = predict(bag.Salary, Validation, type = 'prob')
predic.Validate = predict(rfModel, newdata = Validation)
Conf.Validate = confusionMatrix(Validation$Salary, predic.Validate)
Conf.Validate
df.Validate = cbind(posteriors.Validate[,2], Validation$Salary)
preds.Validate = prediction(df.Validate[,1], df.Validate[,2])
ROC.Validate = performance(preds.Validate, measure = 'tpr', x.measure = 'fpr')
plot(ROC.Validate)
abline(a = 0, b = 1 , lty = 2)
auc.Validate = performance(preds.Validate, measure = 'auc')
auc.Validate@y.values
```

```{r}
posteriors.Validate = predict(rfModel, Validation, type = 'prob')
predic.Validate = predict(rfModel, newdata = Validation)
Conf.Validate = confusionMatrix(Validation$Salary, predic.Validate)
Conf.Validate
df.Validate = cbind(posteriors.Validate[,2], Validation$Salary)
preds.Validate = prediction(df.Validate[,1], df.Validate[,2])
ROC.Validate = performance(preds.Validate, measure = 'tpr', x.measure = 'fpr')
plot(ROC.Validate)
abline(a = 0, b = 1 , lty = 2)
auc.Validate = performance(preds.Validate, measure = 'auc')
auc.Validate@y.values
```